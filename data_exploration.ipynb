{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction on the Amazon Co-Purchase Graph with GNNs\n",
    "\n",
    "## Data and Problem Statement - Overview\n",
    "\n",
    "In this project, I want to explore the use of Graph Neural Networks (GNNs) to model structural relationships in a real-world. I use the Amazon product co-purchasing network and ground-truth communities data on the SNAP repository (link - https://snap.stanford.edu/data/com-Amazon.html)\n",
    "\n",
    "A summary of the data:\n",
    "\n",
    "- This data is based on the \"Customers Who Bought This Item Also Bought\" feature that we see on the Amazon website.\n",
    "- Each node is an Amazon product. \n",
    "- An edge in this graph defines how often a product i has been co-purchased with product j - hence defining product-product relationships. \n",
    "- There is also the concept of a \"community\" for this graph, where each product's category provided in the Amazon catalog is a ground-truth community. Data at this level can also help us understand things that form at a community level.\n",
    "\n",
    "\n",
    "The core task that I want to focus on is **link prediction**:\n",
    "\n",
    "- Given two products, is there a way where we predict whether they should be connected in the co-purchase graph? \n",
    "- This is a classic problem in recommendation systems in e-commerce.\n",
    "- A large part of this graph can be unseen product pairs. There might be a lot of products across these different categories / communities, indicating sparsity (as we will see). \n",
    "- This approach will allows us to evaluate how well structural graph patterns can guide suggestions for these unseen product pairs.\n",
    "\n",
    "\n",
    "Modern recommendation systems focus heavily on how users interact with products in the catalog based on their view / add to cart / purchase patterns, and various other relevant signals that can be interpreted based on their activity on the e-commerce platform. By looking at product-product relationships through a graphical structure, we can gain underlying insights on questions like the following:\n",
    "\n",
    "- Are there specific dominant products (or) communities of products that are linked? How are they connected and how similar are they?\n",
    "- How expressive would node embeddings be by just considering the co-purchase context?\n",
    "- How representative can this data / a model trained on this data be to power recommendation algorithms?\n",
    "\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "\n",
    "1. **Exploring the Amazon co-purchase data**: Parse and visualize the Amazon co-purchase graph. Analyze statistics such as degree distributions, component sizes, clustering, and community structure.\n",
    "3. **Task Framing**: Define the link prediction task as a binary classification problem.\n",
    "4. **Model Development**: Train a GNN to learn node embeddings and use a scoring function to predict links.\n",
    "5. **Evaluation & Insights**: Measure model performance and interpret results both quantitatively and qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Amazon co-purchase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the graph data & summarizing basic overall graph statistics\n",
    "\n",
    "\n",
    "- Let us try to understand the structural properties of our co-purchase graph - to get an idea of how densely the products are connected and whether any global patterns emerge.\n",
    "\n",
    "- Below, we compute and summarize basic statistics of the graph, including the number of nodes and edges, average degree, graph density, clustering coefficient, and details about connectivity. \n",
    "\n",
    "<!-- These statistics not only help validate data quality but also guide how we construct models—for instance, sparse graphs with strong clustering may benefit from localized message passing in GNNs. -->\n",
    "\n",
    "<!-- The **largest connected component** is particularly important, as GNNs rely on connectivity for message propagation. We'll focus our modeling efforts on this component to ensure meaningful learning. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_path):\n",
    "    edges = []\n",
    "    with gzip.open(file_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            source, target = map(int, line.strip().split())\n",
    "            edges.append((source, target))\n",
    "    return nx.Graph(edges)\n",
    "\n",
    "def basic_graph_stats(G):\n",
    "\n",
    "    number_of_nodes = G.number_of_nodes()\n",
    "    number_of_edges = G.number_of_edges()\n",
    "    degrees = dict(G.degree()).values()\n",
    "\n",
    "    stats = {\n",
    "        \"Number of nodes\": number_of_nodes,\n",
    "        \"Number of edges\": number_of_edges,\n",
    "        \"Average degree\": sum(degrees) / number_of_nodes if number_of_nodes > 0 else 0,\n",
    "        \"Density\": nx.density(G),\n",
    "        \"Average clustering coefficient\": nx.average_clustering(G),\n",
    "        \"Number of connected components\": nx.number_connected_components(G),\n",
    "        \"Size of largest component\": len(max(nx.connected_components(G), key=len)) if number_of_nodes > 0 else 0,\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 334863 nodes and 925872 edges.\n",
      "\n",
      "\n",
      "\n",
      "*** OVERALL GRAPH STATISTICS ***\n",
      "\n",
      "{\n",
      "    \"Number of nodes\": 334863,\n",
      "    \"Number of edges\": 925872,\n",
      "    \"Average degree\": 5.529855493141971,\n",
      "    \"Density\": 1.6513834036534368e-05,\n",
      "    \"Average clustering coefficient\": 0.3967463932787655,\n",
      "    \"Number of connected components\": 1,\n",
      "    \"Size of largest component\": 334863\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "graph = load_graph(file_path=\"data/raw/com-amazon.ungraph.txt.gz\")\n",
    "print(f\"Graph has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n",
    "\n",
    "stats = basic_graph_stats(graph)\n",
    "print(\"\\n\\n\\n*** OVERALL GRAPH STATISTICS ***\\n\")\n",
    "print(json.dumps(stats, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-level Insights:\n",
    "\n",
    "\n",
    "- The statistics suggests that each product is co-purchased with 5–6 others on average, which is low in comparison to the overall number of products, and is typical purchase pattern in such platforms. \n",
    "\n",
    "- These 5-6 products that are linked are either similar category or something that complements each other. \n",
    "\n",
    "    - For example, {phone, phone-case, screen-protector} (or) {PS5, additional controller, charger for controllers} might be purchased together as they are contextually related and purchasing them together enhances the usability of the phone or the PS5. \n",
    "    - Another example could be {shampoo, conditioner, hair wax} - all same category and can be likely purchased together because someone wants to invest in hair products.\n",
    "\n",
    "- The graph is **extremely sparse** - a major chunk of products are not linked, as it should be.\n",
    "\n",
    "    - Links only exist for contextually similar or categorically similar products as seen above. \n",
    "    - The whole category has over 300k products and not every product is contextually related.\n",
    "\n",
    "- The average clustering coefficient of this graph is around ~0.4 and this is quite high for such a sparse graph. \n",
    "\n",
    "    - This means that there are some strong local communities.\n",
    "    - If a product A is co-purchased with B and C, then B and C are also very likely co-purchased with each other.\n",
    "\n",
    "- The graph is fully connected - there is a path that connects each product to every other via some sequence of co-purchases.\n",
    "\n",
    "These statistics confirm that the Amazon co-purchase graph exhibits **small-world properties** -  high local clustering and global connectivity (one connected component despite sparsity).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community graph - High level Insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total communities in file: 75149\n",
      "Line 0: '100005\t127545\t202036\t257630\t362970\t376927\t429080'\n",
      "Line 1: '10001\t27638\t51569\t88226\t116422\t126227\t159947\t162938\t184977\t188045\t191044\t246142\t265214\t290507\t296858\t300258\t341525\t348922\t359832\t365744\t382502\t390538\t410857\t433453\t479170\t489980\t540746'\n",
      "Line 2: '10001\t27638\t51569\t88226\t116422\t126227\t159947\t162938\t184977\t188045\t191044\t246142\t265214\t290507\t300258\t341525\t348922\t359832\t365744\t382502\t390538\t410857\t433453\t479170\t489980\t540746'\n",
      "Line 3: '100017\t118111\t263647\t268405\t315862'\n",
      "Line 4: '100020\t267700\t301658\t376628\t410518\t464375'\n",
      "Line 5: '100022\t298856\t412978\t472429'\n",
      "Line 6: '100025\t179592\t260929\t464366'\n",
      "Line 7: '100025\t260929\t328722\t411257'\n",
      "Line 8: '100025\t286364\t301821\t316953\t421421\t467329\t488266\t491602\t519950'\n",
      "Line 9: '100030\t106036\t209079\t289843'\n"
     ]
    }
   ],
   "source": [
    "filepath = \"data/raw/com-amazon.all.dedup.cmty.txt.gz\"\n",
    "all_cmty_nodes = set()\n",
    "with gzip.open(filepath, 'rt') as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total communities in file: {line_count}\")\n",
    "\n",
    "with gzip.open(filepath, 'rt') as f:\n",
    "    for i in range(10):\n",
    "        line = f.readline()\n",
    "        print(f\"Line {i}: '{line.strip()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total communities in file: 5000\n",
      "Line 0: '164985\t225214\t232761'\n",
      "Line 1: '105089\t282815\t331787'\n",
      "Line 2: '167906\t288975\t421279\t442612\t451312'\n",
      "Line 3: '69880\t231953\t518997\t523128'\n",
      "Line 4: '135499\t160294\t304770'\n",
      "Line 5: '112813\t112814\t112821\t112823'\n",
      "Line 6: '112813\t112814\t112821\t112823'\n",
      "Line 7: '199372\t399560\t447268\t471226\t522928'\n",
      "Line 8: '179001\t391697\t412528'\n",
      "Line 9: '21166\t207188\t405926\t531532\t540207'\n"
     ]
    }
   ],
   "source": [
    "filepath = \"data/raw/com-amazon.top5000.cmty.txt.gz\"\n",
    "all_cmty_nodes = set()\n",
    "with gzip.open(filepath, 'rt') as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Total communities in file: {line_count}\")\n",
    "\n",
    "with gzip.open(filepath, 'rt') as f:\n",
    "    for i in range(10):\n",
    "        line = f.readline()\n",
    "        print(f\"Line {i}: '{line.strip()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_communities_subgraph(G, community_path):\n",
    "    community_map = {}\n",
    "    community_id = 0\n",
    "\n",
    "    with gzip.open(community_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            nodes = list(map(int, line.strip().split('\\t')))\n",
    "            for node in nodes:\n",
    "                if node in G and node not in community_map:\n",
    "                    community_map[node] = community_id\n",
    "            community_id += 1\n",
    "\n",
    "    selected_nodes = set(community_map.keys())\n",
    "    G_sub = G.subgraph(selected_nodes).copy()\n",
    "\n",
    "    return G_sub, community_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5000 community subgraph has 16716 nodes and 48739 edges.\n",
      "\n",
      "\n",
      "\n",
      "*** TOP-K COMMUNITY GRAPH STATISTICS ***\n",
      "\n",
      "{\n",
      "    \"Number of nodes\": 16716,\n",
      "    \"Number of edges\": 48739,\n",
      "    \"Average degree\": 5.831418999760708,\n",
      "    \"Density\": 0.00034887340710503786,\n",
      "    \"Average clustering coefficient\": 0.6488186833732773,\n",
      "    \"Number of connected components\": 1106,\n",
      "    \"Size of largest component\": 475\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "_, entire_community_map = extract_top_communities_subgraph(\n",
    "    graph, community_path=\"data/raw/com-amazon.all.dedup.cmty.txt.gz\"\n",
    ")\n",
    "\n",
    "\n",
    "top_k_community_graph, top_k_community_map = extract_top_communities_subgraph(\n",
    "    graph, community_path=\"data/raw/com-amazon.top5000.cmty.txt.gz\"\n",
    ")\n",
    "print(f\"Top-5000 community subgraph has {top_k_community_graph.number_of_nodes()} nodes and {top_k_community_graph.number_of_edges()} edges.\")\n",
    "\n",
    "top_k_community_stats = basic_graph_stats(top_k_community_graph)\n",
    "print(\"\\n\\n\\n*** TOP-K COMMUNITY GRAPH STATISTICS ***\\n\")\n",
    "print(json.dumps(top_k_community_stats, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The top-5000 community subgraph retains similar local structural properties - statistics such as average degree and clustering behavior is the same\n",
    "\n",
    "-  The difference is visible in the global structure - the subgraph is far denser and highly fragmented as there are many disconnected components. Each top community is very strongly interconnected but not very well intraconnected, which was something that we observed in the overall graph.\n",
    "\n",
    "- If we only consider products that only belong to top-5000 communities, then we are not considering edges that go from the top-5000 communities to other products that are not part of the top-5000 communities. Those bridge edges are lost here.\n",
    "\n",
    "- Let us try to include the bridge edges for all the nodes and analyse again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting this function\n",
    "def extract_top_communities_subgraph(G, community_path):\n",
    "    import gzip\n",
    "\n",
    "    community_map = {}\n",
    "    community_id = 0\n",
    "\n",
    "    # Read top-k communities and build the node set\n",
    "    with gzip.open(community_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            nodes = list(map(int, line.strip().split('\\t')))\n",
    "            for node in nodes:\n",
    "                if node in G and node not in community_map:\n",
    "                    community_map[node] = community_id\n",
    "            community_id += 1\n",
    "\n",
    "    top_k_nodes = set(community_map.keys())\n",
    "\n",
    "    # Include all edges where at least one node is in top-k\n",
    "    expanded_edges = [(u, v) for u, v in G.edges() if u in top_k_nodes or v in top_k_nodes]\n",
    "\n",
    "    # Build the new graph\n",
    "    G_expanded = nx.Graph()\n",
    "    G_expanded.add_edges_from(expanded_edges)\n",
    "\n",
    "    return G_expanded, community_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5000 expanded subgraph has 19905 nodes and 53780 edges\n",
      "\n",
      "\n",
      "\n",
      "*** TOP-K COMMUNITY EXPANDED GRAPH STATISTICS ***\n",
      "\n",
      "{\n",
      "    \"Number of nodes\": 19905,\n",
      "    \"Number of edges\": 53780,\n",
      "    \"Average degree\": 5.403667420246169,\n",
      "    \"Density\": 0.0002714865062422714,\n",
      "    \"Average clustering coefficient\": 0.5384229737133063,\n",
      "    \"Number of connected components\": 1044,\n",
      "    \"Size of largest component\": 481\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "top_k_community_expanded_graph, top_k_community_expanded_map = extract_top_communities_subgraph(graph, \"data/raw/com-amazon.top5000.cmty.txt.gz\")\n",
    "\n",
    "print(f\"Top-5000 expanded subgraph has {top_k_community_expanded_graph.number_of_nodes()} nodes and {top_k_community_expanded_graph.number_of_edges()} edges\")\n",
    "\n",
    "top_k_community_expanded_stats = basic_graph_stats(top_k_community_expanded_graph)\n",
    "print(\"\\n\\n\\n*** TOP-K COMMUNITY EXPANDED GRAPH STATISTICS ***\\n\")\n",
    "print(json.dumps(top_k_community_expanded_stats, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are around ~5k new edges added and all of these are bridge edges, which add important context of co-purchasing patterns.\n",
    "\n",
    "- The average degree distribution is still consistent, and the clustering coefficient slightly drops and is now closer to the distributions in the overall graph.\n",
    "\n",
    "- Fragmentation has slightly reduced because of the introduction to the bridge edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Analysis\n",
    "\n",
    "- Analyzing community structure helps reveal more information about graph relationships. \n",
    "\n",
    "- It can convey information about how consumers navigate the catalog, whether they buy within or across contexts and categories, and what kind of structural patterns govern co-purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_intra_community_edges(G_sub, community_map):\n",
    "    intra = inter = ignored = 0\n",
    "\n",
    "    for u, v in G_sub.edges():\n",
    "        cu, cv = community_map.get(u), community_map.get(v)\n",
    "        if cu is None or cv is None:\n",
    "            ignored += 1\n",
    "            continue\n",
    "        if cu == cv:\n",
    "            intra += 1\n",
    "        else:\n",
    "            inter += 1\n",
    "\n",
    "    print(f\"Intra-community edges: {intra}\")\n",
    "    print(f\"Inter-community edges: {inter}\")\n",
    "    print(f\"Ignored (unassigned): {ignored}\")\n",
    "    print(f\"Modularity-like ratio: {intra / (intra + inter):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes with community assignment: 317194 out of 334863\n",
      "Unassigned nodes: 17669\n"
     ]
    }
   ],
   "source": [
    "assigned_nodes = set(entire_community_map.keys())\n",
    "print(f\"Nodes with community assignment: {len(assigned_nodes)} out of {graph.number_of_nodes()}\")\n",
    "\n",
    "unassigned_nodes = set(graph.nodes()) - assigned_nodes\n",
    "print(f\"Unassigned nodes: {len(unassigned_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-community edges: 485242\n",
      "Inter-community edges: 387693\n",
      "Ignored (unassigned): 52937\n",
      "Modularity-like ratio: 0.5559\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Intra-community edges: 47502\n",
      "Inter-community edges: 1237\n",
      "Ignored (unassigned): 0\n",
      "Modularity-like ratio: 0.9746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Intra-community edges: 47502\n",
      "Inter-community edges: 1237\n",
      "Ignored (unassigned): 5041\n",
      "Modularity-like ratio: 0.9746\n"
     ]
    }
   ],
   "source": [
    "get_inter_intra_community_edges(graph, entire_community_map)\n",
    "print(\"\\n\\n\\n\")\n",
    "get_inter_intra_community_edges(top_k_community_graph, top_k_community_map)\n",
    "print(\"\\n\\n\\n\")\n",
    "get_inter_intra_community_edges(top_k_community_expanded_graph, top_k_community_expanded_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned community IDs: 1399 / 5000\n",
      "Communities with no overlap: 0 / 5000\n",
      "Assigned 1399 communities\n"
     ]
    }
   ],
   "source": [
    "all_community_ids = set()\n",
    "with gzip.open(\"data/raw/com-amazon.top5000.cmty.txt.gz\", 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5000:\n",
    "            break\n",
    "        all_community_ids.add(i)\n",
    "\n",
    "# How many of these are actually assigned?\n",
    "assigned_ids = set(top_k_community_map.values())\n",
    "print(f\"Assigned community IDs: {len(assigned_ids)} / {len(all_community_ids)}\")\n",
    "\n",
    "# Load all node IDs from ungraph\n",
    "G_nodes = set(graph.nodes())\n",
    "\n",
    "# Count how many nodes in top-5000 file are missing from ungraph\n",
    "missing = 0\n",
    "total = 0\n",
    "with gzip.open(\"data/raw/com-amazon.top5000.cmty.txt.gz\", 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5000: break\n",
    "        nodes = set(map(int, line.strip().split('\\t')))\n",
    "        total += 1\n",
    "        if not nodes & G_nodes:\n",
    "            missing += 1\n",
    "\n",
    "print(f\"Communities with no overlap: {missing} / {total}\")\n",
    "\n",
    "active_communities = set(top_k_community_expanded_map.values())\n",
    "print(f\"Assigned {len(active_communities)} communities\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18535, 1399, 1399)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(entire_community_map.values())), len(set(top_k_community_map.values())), len(set(top_k_community_expanded_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full graph:\n",
    "\n",
    "- The **full graph** shows a much lower ratio of ~0.5.\n",
    "\n",
    "    - Although we saw local clusters exist from our previous analysis, a large portion of edges in the graph are cross-community (in this case, cross-category). \n",
    "\n",
    "- The **top-5000 community graph** shows high ratio that is almost 0.99. This top-5000 is well-defined and  \n",
    "\n",
    "- Around 53,000 edges involve some node or both nodes without any community assignment (the ground truth does not exist) and for those edges we cannot predict insights at a community level.\n",
    "\n",
    "\n",
    "### Top-5000 community graph:\n",
    "\n",
    "- 98.6% of edges in the top-5000 community subgraph connect nodes **within the same community**. Only 671 edges span across different communities.\n",
    "\n",
    "- This confirms that in the top-5000 communities, the product-product relationships are **highly self-contained** - most co-purchases only mostly happen within a localized group.\n",
    "\n",
    "- This structural separation is consistent with real-world behavior, where users typically shop within narrow product scopes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
