{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction on the Amazon Co-Purchase Graph with GNNs\n",
    "\n",
    "## Data and Problem Statement - Overview\n",
    "\n",
    "In this project, I want to explore the use of Graph Neural Networks (GNNs) to model structural relationships in a real-world. I use the Amazon product co-purchasing network and ground-truth communities data on the SNAP repository (link - https://snap.stanford.edu/data/com-Amazon.html)\n",
    "\n",
    "A summary of the data:\n",
    "\n",
    "- This data is based on the \"Customers Who Bought This Item Also Bought\" feature that we see on the Amazon website.\n",
    "- Each node is an Amazon product. \n",
    "- An edge in this graph defines how often a product i has been co-purchased with product j - hence defining product-product relationships. \n",
    "- There is also the concept of a \"community\" for this graph, where each product's category provided in the Amazon catalog is a ground-truth community. Data at this level can also help us understand things that form at a community level.\n",
    "\n",
    "\n",
    "The core task that I want to focus on is **link prediction**:\n",
    "\n",
    "- Given two products, is there a way where we predict whether they should be connected in the co-purchase graph? \n",
    "- This is a classic problem in recommendation systems in e-commerce.\n",
    "- A large part of this graph can be unseen product pairs. There might be a lot of products across these different categories / communities, indicating sparsity (as we will see). \n",
    "- This approach will allows us to evaluate how well structural graph patterns can guide suggestions for these unseen product pairs.\n",
    "\n",
    "\n",
    "Modern recommendation systems focus heavily on how users interact with products in the catalog based on their view / add to cart / purchase patterns, and various other relevant signals that can be interpreted based on their activity on the e-commerce platform. By looking at product-product relationships through a graphical structure, we can gain underlying insights on questions like the following:\n",
    "\n",
    "- Are there specific dominant products (or) communities of products that are linked? How are they connected and how similar are they?\n",
    "- How expressive would node embeddings be by just considering the co-purchase context?\n",
    "- How representative can this data / a model trained on this data be to power recommendation algorithms?\n",
    "\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "\n",
    "1. **Exploring the Amazon co-purchase data**: Parse and visualize the Amazon co-purchase graph. Analyze statistics such as degree distributions, component sizes, clustering, and community structure.\n",
    "3. **Task Framing**: Define the link prediction task as a binary classification problem.\n",
    "4. **Model Development**: Train a GNN to learn node embeddings and use a scoring function to predict links.\n",
    "5. **Evaluation & Insights**: Measure model performance and interpret results both quantitatively and qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from scripts import utils as U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Amazon co-purchase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the graph data & summarizing basic overall graph statistics\n",
    "\n",
    "\n",
    "- Let us try to understand the structural properties of our co-purchase graph - to get an idea of how densely the products are connected and whether any global patterns emerge.\n",
    "\n",
    "- Below, we compute and summarize basic statistics of the graph, including the number of nodes and edges, average degree, graph density, clustering coefficient, and details about connectivity. \n",
    "\n",
    "<!-- These statistics not only help validate data quality but also guide how we construct modelsâ€”for instance, sparse graphs with strong clustering may benefit from localized message passing in GNNs. -->\n",
    "\n",
    "<!-- The **largest connected component** is particularly important, as GNNs rely on connectivity for message propagation. We'll focus our modeling efforts on this component to ensure meaningful learning. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_path):\n",
    "    edges = []\n",
    "    with gzip.open(file_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            source, target = map(int, line.strip().split())\n",
    "            edges.append((source, target))\n",
    "    return nx.Graph(edges)\n",
    "\n",
    "def basic_graph_stats(G):\n",
    "    \"\"\"Calculate and return basic statistics about the graph G.\"\"\"\n",
    "    number_of_nodes = G.number_of_nodes()\n",
    "    number_of_edges = G.number_of_edges()\n",
    "    degrees = dict(G.degree()).values()\n",
    "\n",
    "    stats = {\n",
    "        \"Number of nodes\": number_of_nodes,\n",
    "        \"Number of edges\": number_of_edges,\n",
    "        \"Average degree\": sum(degrees) / number_of_nodes if number_of_nodes > 0 else 0,\n",
    "        \"Density\": nx.density(G),\n",
    "        \"Average clustering coefficient\": nx.average_clustering(G),\n",
    "        \"Number of connected components\": nx.number_connected_components(G),\n",
    "        \"Size of largest component\": len(max(nx.connected_components(G), key=len)) if number_of_nodes > 0 else 0,\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 334863 nodes and 925872 edges.\n",
      "\n",
      "\n",
      "\n",
      "*** OVERALL GRAPH STATISTICS ***\n",
      "\n",
      "{\n",
      "    \"Number of nodes\": 334863,\n",
      "    \"Number of edges\": 925872,\n",
      "    \"Average degree\": 5.529855493141971,\n",
      "    \"Density\": 1.6513834036534368e-05,\n",
      "    \"Average clustering coefficient\": 0.3967463932788733,\n",
      "    \"Number of connected components\": 1,\n",
      "    \"Size of largest component\": 334863\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "graph = load_graph(file_path=\"data/raw/com-amazon.ungraph.txt.gz\")\n",
    "print(f\"Graph has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n",
    "\n",
    "stats = basic_graph_stats(graph)\n",
    "print(\"\\n\\n\\n*** OVERALL GRAPH STATISTICS ***\\n\")\n",
    "print(json.dumps(stats, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohan-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
